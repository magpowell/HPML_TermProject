{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4aK3MI9qhfJ"
      },
      "outputs": [],
      "source": [
        "import os, sys, time\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.insert(1, './FourCastNet/') # insert code repo into path\n",
        "from utils.YParams import YParams\n",
        "from networks.afnonet import AFNONet\n",
        "\n",
        "from constants import VARIABLES\n",
        "from proj_utils import load_model, inference, lat, latitude_weighting_factor, weighted_rmse_channels\n",
        "from distributed_utils import inference_ensemble\n",
        "\n",
        "PLOT_INPUTS = False # to get a sample plot\n",
        " \n",
        "# you can use conda env create -f environment.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qh5FKi6Nopbr"
      },
      "outputs": [],
      "source": [
        "# DO THIS WITHIN YOUR SCRATCH AND SET PATH\n",
        "# wget https://portal.nersc.gov/project/m4134/ccai_demo.tar\n",
        "# tar -xvf ccai_demo.tar\n",
        "# rm ccai_demo.tar\n",
        "\n",
        "base_path = \"/pscratch/sd/m/mpowell/hpml/\" # update to yours\n",
        "\n",
        "# data and model paths\n",
        "data_path = f\"{base_path}ccai_demo/data/FCN_ERA5_data_v0/out_of_sample\"\n",
        "data_file = os.path.join(data_path, \"2018.h5\")\n",
        "model_path = f\"{base_path}ccai_demo/model_weights/FCN_weights_v0/backbone.ckpt\"\n",
        "global_means_path = f\"{base_path}ccai_demo/additional/stats_v0/global_means.npy\"\n",
        "global_stds_path = f\"{base_path}ccai_demo/additional/stats_v0/global_stds.npy\"\n",
        "time_means_path = f\"{base_path}ccai_demo/additional/stats_v0/time_means.npy\"\n",
        "land_sea_mask_path = f\"{base_path}ccai_demo/additional/stats_v0/land_sea_mask.npy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndWgztWUiAo5",
        "outputId": "a321bd96-10a4-437d-c122-d3e40af97db9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model architecture used = afno\n"
          ]
        }
      ],
      "source": [
        "# default\n",
        "config_file = \"./FourCastNet/config/AFNO.yaml\"\n",
        "config_name = \"afno_backbone\"\n",
        "params = YParams(config_file, config_name)\n",
        "print(\"Model architecture used = {}\".format(params[\"nettype\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "vn9NT0SLjUZS",
        "outputId": "d76b58c0-bf12-42da-90c1-dcfc0f557e95"
      },
      "outputs": [],
      "source": [
        "if PLOT_INPUTS:\n",
        "    sample_data = h5py.File(data_file, 'r')['fields']\n",
        "    print('Total data shape:', sample_data.shape)\n",
        "    timestep_idx = 0\n",
        "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
        "    for i, varname in enumerate(['u10', 't2m', 'z500', 'tcwv']):\n",
        "        cm = 'bwr' if varname == 'u10' or varname == 'z500' else 'viridis'\n",
        "        varidx = VARIABLES.index(varname)\n",
        "        ax[i//2][i%2].imshow(sample_data[timestep_idx, varidx], cmap=cm)\n",
        "        ax[i//2][i%2].set_title(varname)\n",
        "    fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "506dCT1UiAo6"
      },
      "outputs": [],
      "source": [
        "# import model\n",
        "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# in and out channels: FourCastNet uses 20 input channels corresponding to 20 prognostic variables\n",
        "in_channels = np.array(params.in_channels)\n",
        "out_channels = np.array(params.out_channels)\n",
        "params['N_in_channels'] = len(in_channels)\n",
        "params['N_out_channels'] = len(out_channels)\n",
        "params.means = np.load(global_means_path)[0, out_channels] # for normalizing data with precomputed train stats\n",
        "params.stds = np.load(global_stds_path)[0, out_channels]\n",
        "params.time_means = np.load(time_means_path)[0, out_channels]\n",
        "\n",
        "# load the model\n",
        "if params.nettype == 'afno':\n",
        "    model = AFNONet(params).to(device)  # AFNO model\n",
        "else:\n",
        "    raise Exception(\"not implemented\")\n",
        "# load saved model weights\n",
        "model = load_model(model, params, model_path)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CeKQHfyrU7k",
        "outputId": "f2ec362f-4598-49d7-ae74-6f3472d9c9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of time means = torch.Size([1, 20, 720, 1440])\n",
            "Shape of std = torch.Size([20])\n"
          ]
        }
      ],
      "source": [
        "# move normalization tensors to gpu\n",
        "# load time means: represents climatology\n",
        "img_shape_x = 720\n",
        "img_shape_y = 1440\n",
        "\n",
        "# means and stds over training data\n",
        "means = params.means\n",
        "stds = params.stds\n",
        "\n",
        "# load climatological means\n",
        "time_means = params.time_means # temporal mean (for every pixel)\n",
        "m = torch.as_tensor((time_means - means)/stds)[:, 0:img_shape_x]\n",
        "m = torch.unsqueeze(m, 0)\n",
        "# these are needed to compute ACC and RMSE metrics\n",
        "m = m.to(device, dtype=torch.float)\n",
        "std = torch.as_tensor(stds[:,0,0]).to(device, dtype=torch.float)\n",
        "\n",
        "print(\"Shape of time means = {}\".format(m.shape))\n",
        "print(\"Shape of std = {}\".format(std.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBgMrdTeiAo9",
        "outputId": "8c1baf38-fb21-4499-d08b-a440febb2f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading inference data\n",
            "Inference data from /pscratch/sd/m/mpowell/hpml/ccai_demo/data/FCN_ERA5_data_v0/out_of_sample/2018.h5\n",
            "(20, 20, 720, 1440)\n",
            "Shape of data = (20, 20, 720, 1440)\n"
          ]
        }
      ],
      "source": [
        "# setup data for inference\n",
        "dt = 1 # time step (x 6 hours)\n",
        "ic = 0 # start the inference from here\n",
        "prediction_length = 20 # number of steps (x 6 hours)\n",
        "\n",
        "# which field to track for visualization\n",
        "field = 'u10'\n",
        "idx_vis = VARIABLES.index(field) # also prints out metrics for this field\n",
        "\n",
        "# get prediction length slice from the data\n",
        "print('Loading inference data')\n",
        "print('Inference data from {}'.format(data_file))\n",
        "data = h5py.File(data_file, 'r')['fields'][ic:(ic+prediction_length*dt):dt,in_channels,0:img_shape_x]\n",
        "print(data.shape)\n",
        "print(\"Shape of data = {}\".format(data.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prVSKVzaiAo-",
        "outputId": "f99e2752-2c37-4b25-e887-f451e15c1675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted timestep 0 of 20. u10 RMS Error: 0.0, ACC: 1.0\n",
            "Predicted timestep 1 of 20. u10 RMS Error: 0.5596160888671875, ACC: 0.9900780916213989\n",
            "Predicted timestep 2 of 20. u10 RMS Error: 0.7683386206626892, ACC: 0.9802827835083008\n",
            "Predicted timestep 3 of 20. u10 RMS Error: 0.8545043468475342, ACC: 0.9751383066177368\n",
            "Predicted timestep 4 of 20. u10 RMS Error: 0.9779791831970215, ACC: 0.966327965259552\n",
            "Predicted timestep 5 of 20. u10 RMS Error: 1.0723881721496582, ACC: 0.9600257873535156\n",
            "Predicted timestep 6 of 20. u10 RMS Error: 1.2339807748794556, ACC: 0.946362316608429\n",
            "Predicted timestep 7 of 20. u10 RMS Error: 1.3772971630096436, ACC: 0.9345548152923584\n",
            "Predicted timestep 8 of 20. u10 RMS Error: 1.5802643299102783, ACC: 0.9138451814651489\n",
            "Predicted timestep 9 of 20. u10 RMS Error: 1.7349448204040527, ACC: 0.9004244208335876\n",
            "Predicted timestep 10 of 20. u10 RMS Error: 1.9254651069641113, ACC: 0.8790378570556641\n",
            "Predicted timestep 11 of 20. u10 RMS Error: 2.1220521926879883, ACC: 0.8571361303329468\n",
            "Predicted timestep 12 of 20. u10 RMS Error: 2.304060935974121, ACC: 0.8303263187408447\n",
            "Predicted timestep 13 of 20. u10 RMS Error: 2.4981000423431396, ACC: 0.8087863922119141\n",
            "Predicted timestep 14 of 20. u10 RMS Error: 2.7439069747924805, ACC: 0.7700998187065125\n",
            "Predicted timestep 15 of 20. u10 RMS Error: 2.964310884475708, ACC: 0.7334862947463989\n",
            "Predicted timestep 16 of 20. u10 RMS Error: 3.165731906890869, ACC: 0.6908555626869202\n",
            "Predicted timestep 17 of 20. u10 RMS Error: 3.3164660930633545, ACC: 0.6700968742370605\n",
            "Predicted timestep 18 of 20. u10 RMS Error: 3.400787353515625, ACC: 0.6364221572875977\n",
            "Predicted timestep 19 of 20. u10 RMS Error: 3.4145820140838623, ACC: 0.6138813495635986\n"
          ]
        }
      ],
      "source": [
        "# run inference\n",
        "data = (data - means)/stds # standardize the data\n",
        "data = torch.as_tensor(data).to(device, dtype=torch.float) # move to gpu for inference\n",
        "acc_cpu, rmse_cpu, predictions_cpu, targets_cpu = inference(data, model, prediction_length, idx=idx_vis,\n",
        "                                                            params = params, device = device, \n",
        "                                                            img_shape_x = img_shape_x, img_shape_y = img_shape_y, std = std, m =m, field = field)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uQxb0APYOgat"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total inference time for 2 ensemble members over 20 steps: 6.016 seconds\n"
          ]
        }
      ],
      "source": [
        "ensemble_size = 2\n",
        "base_initial = data[0:1]  # shape: [1, channels, img_shape_x, img_shape_y]\n",
        "\n",
        "# replicate to create an ensemble and add a small perturbation (e.g., 1e-3 scaling factor)\n",
        "ensemble_init = base_initial.repeat(ensemble_size, 1, 1, 1)\n",
        "epsilon = 1e-3  # perturbation magnitude\n",
        "ensemble_init += epsilon * torch.randn_like(ensemble_init)\n",
        "\n",
        "# Set the prediction length (number of autoregressive steps)\n",
        "prediction_length = 20  # as before\n",
        "\n",
        "# Run the ensemble inference and measure the performance\n",
        "ensemble_predictions, inference_time = inference_ensemble(ensemble_init, model, prediction_length, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
