{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(1, './FourCastNet/') # insert code repo into path\n",
    "\n",
    "# you may need to\n",
    "# !pip install ruamel.yaml einops timm\n",
    "# (or conda install)\n",
    "\n",
    "from utils.YParams import YParams\n",
    "from networks.afnonet import AFNONet\n",
    "\n",
    "from constants import VARIABLES\n",
    "from proj_utils import load_model, inference, lat, latitude_weighting_factor, weighted_rmse_channels\n",
    "\n",
    "PLOT_INPUTS = False # to get a sample plot\n",
    "COMPILE = True # to use torch.compile()\n",
    "\n",
    "# DO THIS WITHIN YOUR SCRATCH AND SET PATH\n",
    "# wget https://portal.nersc.gov/project/m4134/ccai_demo.tar\n",
    "# tar -xvf ccai_demo.tar\n",
    "# rm ccai_demo.tar\n",
    "\n",
    "base_path = \"/pscratch/sd/m/mpowell/hpml/\"\n",
    "\n",
    "# data and model paths\n",
    "data_path = f\"{base_path}ccai_demo/data/FCN_ERA5_data_v0/out_of_sample\"\n",
    "data_file = os.path.join(data_path, \"2018.h5\")\n",
    "model_path = f\"{base_path}ccai_demo/model_weights/FCN_weights_v0/backbone.ckpt\"\n",
    "global_means_path = f\"{base_path}ccai_demo/additional/stats_v0/global_means.npy\"\n",
    "global_stds_path = f\"{base_path}ccai_demo/additional/stats_v0/global_stds.npy\"\n",
    "time_means_path = f\"{base_path}ccai_demo/additional/stats_v0/time_means.npy\"\n",
    "land_sea_mask_path = f\"{base_path}ccai_demo/additional/stats_v0/land_sea_mask.npy\"\n",
    "\n",
    "# default\n",
    "config_file = \"./FourCastNet/config/AFNO.yaml\"\n",
    "config_name = \"afno_backbone\"\n",
    "params = YParams(config_file, config_name)\n",
    "print(\"Model architecture used = {}\".format(params[\"nettype\"]))\n",
    "\n",
    "if PLOT_INPUTS:\n",
    "    sample_data = h5py.File(data_file, 'r')['fields']\n",
    "    print('Total data shape:', sample_data.shape)\n",
    "    timestep_idx = 0\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "    for i, varname in enumerate(['u10', 't2m', 'z500', 'tcwv']):\n",
    "        cm = 'bwr' if varname == 'u10' or varname == 'z500' else 'viridis'\n",
    "        varidx = VARIABLES.index(varname)\n",
    "        ax[i//2][i%2].imshow(sample_data[timestep_idx, varidx], cmap=cm)\n",
    "        ax[i//2][i%2].set_title(varname)\n",
    "    fig.tight_layout()\n",
    "\n",
    "# import model\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# in and out channels: FourCastNet uses 20 input channels corresponding to 20 prognostic variables\n",
    "in_channels = np.array(params.in_channels)\n",
    "out_channels = np.array(params.out_channels)\n",
    "params['N_in_channels'] = len(in_channels)\n",
    "params['N_out_channels'] = len(out_channels)\n",
    "params.means = np.load(global_means_path)[0, out_channels] # for normalizing data with precomputed train stats\n",
    "params.stds = np.load(global_stds_path)[0, out_channels]\n",
    "params.time_means = np.load(time_means_path)[0, out_channels]\n",
    "\n",
    "# load the model\n",
    "if params.nettype == 'afno':\n",
    "    model = AFNONet(params).to(device)  # AFNO model\n",
    "else:\n",
    "    raise Exception(\"not implemented\")\n",
    "# load saved model weights\n",
    "model = load_model(model, params, model_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move normalization tensors to gpu\n",
    "# load time means: represents climatology\n",
    "img_shape_x = 720\n",
    "img_shape_y = 1440\n",
    "\n",
    "# means and stds over training data\n",
    "means = params.means\n",
    "stds = params.stds\n",
    "\n",
    "# load climatological means\n",
    "time_means = params.time_means # temporal mean (for every pixel)\n",
    "m = torch.as_tensor((time_means - means)/stds)[:, 0:img_shape_x]\n",
    "m = torch.unsqueeze(m, 0)\n",
    "# these are needed to compute ACC and RMSE metrics\n",
    "m = m.to(device, dtype=torch.float)\n",
    "std = torch.as_tensor(stds[:,0,0]).to(device, dtype=torch.float)\n",
    "\n",
    "print(\"Shape of time means = {}\".format(m.shape))\n",
    "print(\"Shape of std = {}\".format(std.shape))\n",
    "\n",
    "# setup data for inference\n",
    "dt = 1 # time step (x 6 hours)\n",
    "ic = 0 # start the inference from here\n",
    "prediction_length = 20 # number of steps (x 6 hours)\n",
    "\n",
    "# which field to track for visualization\n",
    "field = 'u10'\n",
    "idx_vis = VARIABLES.index(field) # also prints out metrics for this field\n",
    "\n",
    "# get prediction length slice from the data\n",
    "print('Loading inference data')\n",
    "print('Inference data from {}'.format(data_file))\n",
    "data = h5py.File(data_file, 'r')['fields'][ic:(ic+prediction_length*dt):dt,in_channels,0:img_shape_x]\n",
    "print(data.shape)\n",
    "print(\"Shape of data = {}\".format(data.shape))\n",
    "\n",
    "data = (data - means)/stds # standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[np.newaxis, :, :, :]\n",
    "ensemble_size = 2\n",
    "\n",
    "# replicate to create an ensemble and add a small perturbation (e.g., 1e-3 scaling factor)\n",
    "ensemble_init = data.repeat(ensemble_size, axis = 0)\n",
    "ensemble_init = torch.tensor(ensemble_init, device=device, dtype=torch.float)\n",
    "\n",
    "epsilon = 1e-3  # perturbation magnitude\n",
    "ensemble_init += epsilon * torch.randn_like(ensemble_init.clone().detach())\n",
    "\n",
    "# Set the prediction length (number of autoregressive steps)\n",
    "prediction_length = 20  # as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rmse_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    #takes in arrays of size [n, c, h, w]  and returns latitude-weighted rmse for each channel\n",
    "    num_lat = pred.shape[2]\n",
    "    lat_t = torch.arange(start=0, end=num_lat, device=pred.device)\n",
    "    s = torch.sum(torch.cos(3.1416/180. * lat(lat_t, num_lat)))\n",
    "    weight = torch.reshape(latitude_weighting_factor(lat_t, num_lat, s), (1, 1, -1, 1))\n",
    "    result = torch.sqrt(torch.mean(weight * (pred - target)**2., dim=(-1,-2)))\n",
    "    return result\n",
    "\n",
    "def weighted_acc_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    #takes in arrays of size [n, c, h, w]  and returns latitude-weighted acc for each channel\n",
    "    num_lat = pred.shape[2]\n",
    "    lat_t = torch.arange(start=0, end=num_lat, device=pred.device)\n",
    "    s = torch.sum(torch.cos(3.1416/180. * lat(lat_t, num_lat)))\n",
    "    weight = torch.reshape(latitude_weighting_factor(lat_t, num_lat, s), (1, 1, -1, 1))\n",
    "    result = torch.sum(weight * pred * target, dim=(-1,-2)) / torch.sqrt(torch.sum(weight * pred * pred, dim=(-1,-2)) * torch.sum(weight * target *\n",
    "    target, dim=(-1,-2)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_distributed():\n",
    "    \"\"\"Initialize the distributed environment.\"\"\"\n",
    "    if 'RANK' not in os.environ:\n",
    "        os.environ['RANK'] = '0'\n",
    "    if 'WORLD_SIZE' not in os.environ:\n",
    "        os.environ['WORLD_SIZE'] = '2'\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    \n",
    "    dist.init_process_group(backend='nccl', init_method='env://')\n",
    "    torch.cuda.set_device(int(os.environ['LOCAL_RANK']))\n",
    "    \n",
    "    return int(os.environ['RANK']), int(os.environ['WORLD_SIZE'])\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Clean up the distributed environment.\"\"\"\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e25b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up distributed environment\n",
    "rank, world_size = setup_distributed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share model across processes\n",
    "model = torch.nn.parallel.DistributedDataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide ensemble members among processes\n",
    "local_ensemble_size = (ensemble_size + world_size - 1) // world_size\n",
    "start_idx = rank * local_ensemble_size\n",
    "end_idx = min(start_idx + local_ensemble_size, ensemble_size)\n",
    "local_ensemble_range = range(start_idx, end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process local ensemble members\n",
    "local_results = []\n",
    "for i in local_ensemble_range:\n",
    "    data_slice = ensemble_init[i]\n",
    "    idx = idx_vis\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dummy_input = torch.randn(1, data_slice.shape[1], img_shape_x, img_shape_y).to(device)\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "    # Create memory for the different stats\n",
    "    n_out_channels = params['N_out_channels']\n",
    "    acc = torch.zeros((prediction_length, n_out_channels)).to(device, dtype=torch.float)\n",
    "    rmse = torch.zeros((prediction_length, n_out_channels)).to(device, dtype=torch.float)\n",
    "\n",
    "    # To conserve GPU mem, only save one channel (can be changed if sufficient GPU mem or move to CPU)\n",
    "    targets = torch.zeros((prediction_length, 1, img_shape_x, img_shape_y)).to(device, dtype=torch.float)\n",
    "    predictions = torch.zeros((prediction_length, 1, img_shape_x, img_shape_y)).to(device, dtype=torch.float)\n",
    "\n",
    "    total_time = 0\n",
    "    with torch.no_grad():\n",
    "        for j in range(data_slice.shape[0]):\n",
    "            iter_start = time.time()\n",
    "            if j == 0:\n",
    "                first = data_slice[0:1]\n",
    "                future = data_slice[1:2]\n",
    "                pred = first\n",
    "                tar = first\n",
    "                # Predict\n",
    "                future_pred = model(first)\n",
    "            else:\n",
    "                if j < prediction_length - 1:\n",
    "                    future = data_slice[j+1:j+2]\n",
    "                future_pred = model(future_pred)  # Autoregressive step\n",
    "\n",
    "            if j < prediction_length - 1:\n",
    "                predictions[j+1, 0] = future_pred[0, idx]\n",
    "                targets[j+1, 0] = future[0, idx]\n",
    "            rmse[j] = weighted_rmse_channels(pred, tar) * std\n",
    "            acc[j] = weighted_acc_channels(pred-m, tar-m)\n",
    "            iter_time = time.time() - iter_start\n",
    "            \n",
    "            if rank == 0:  # Only main process logs\n",
    "                print(f'Ensemble {i}, Predicted timestep {j} of {prediction_length}. {field} RMS Error: {rmse[j, idx]}, ACC: {acc[j, idx]}')\n",
    "\n",
    "            pred = future_pred\n",
    "            tar = future\n",
    "            total_time += iter_time\n",
    "            \n",
    "    avg_time = total_time / prediction_length\n",
    "    if rank == 0:\n",
    "        print(f'Ensemble {i}, Total inference time: {total_time:.2f}s, Average time per step: {avg_time:.2f}s')\n",
    "\n",
    "    # Save local results\n",
    "    local_results.append({\n",
    "        'ensemble_idx': i,\n",
    "        'acc': acc.cpu(),\n",
    "        'rmse': rmse.cpu(),\n",
    "        'total_time': total_time,\n",
    "        'avg_time': avg_time\n",
    "    })\n",
    "\n",
    "# Gather results from all processes\n",
    "all_results = [None for _ in range(world_size)]\n",
    "dist.all_gather_object(all_results, local_results)\n",
    "\n",
    "# Flatten the list of results\n",
    "if rank == 0:  # Only main process handles combined results\n",
    "    combined_results = []\n",
    "    for process_results in all_results:\n",
    "        combined_results.extend(process_results)\n",
    "    \n",
    "    # Sort by ensemble index\n",
    "    combined_results.sort(key=lambda x: x['ensemble_idx'])\n",
    "    \n",
    "    # Log combined metrics\n",
    "    for result in combined_results:\n",
    "        i = result['ensemble_idx']\n",
    "        acc = result['acc']\n",
    "        rmse = result['rmse']\n",
    "        predictions = result['predictions'] \n",
    "        targets = result['targets']\n",
    "        total_time = result['total_time']\n",
    "        avg_time = result['avg_time']\n",
    "        \n",
    "# Clean up\n",
    "cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
