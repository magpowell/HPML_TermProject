{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9883b2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/m/mpowell/.conda/envs/hpml_env/lib/python3.13/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture used = afno\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(1, './FourCastNet/') # insert code repo into path\n",
    "\n",
    "# you may need to\n",
    "# !pip install ruamel.yaml einops timm\n",
    "# (or conda install)\n",
    "\n",
    "from utils.YParams import YParams\n",
    "from networks.afnonet import AFNONet\n",
    "\n",
    "from constants import VARIABLES\n",
    "from proj_utils import load_model, inference, lat, latitude_weighting_factor, weighted_rmse_channels\n",
    "\n",
    "PLOT_INPUTS = False # to get a sample plot\n",
    "COMPILE = True # to use torch.compile()\n",
    "\n",
    "# DO THIS WITHIN YOUR SCRATCH AND SET PATH\n",
    "# wget https://portal.nersc.gov/project/m4134/ccai_demo.tar\n",
    "# tar -xvf ccai_demo.tar\n",
    "# rm ccai_demo.tar\n",
    "\n",
    "base_path = \"/pscratch/sd/m/mpowell/hpml/\"\n",
    "\n",
    "# data and model paths\n",
    "data_path = f\"{base_path}ccai_demo/data/FCN_ERA5_data_v0/out_of_sample\"\n",
    "data_file = os.path.join(data_path, \"2018.h5\")\n",
    "model_path = f\"{base_path}ccai_demo/model_weights/FCN_weights_v0/backbone.ckpt\"\n",
    "global_means_path = f\"{base_path}ccai_demo/additional/stats_v0/global_means.npy\"\n",
    "global_stds_path = f\"{base_path}ccai_demo/additional/stats_v0/global_stds.npy\"\n",
    "time_means_path = f\"{base_path}ccai_demo/additional/stats_v0/time_means.npy\"\n",
    "land_sea_mask_path = f\"{base_path}ccai_demo/additional/stats_v0/land_sea_mask.npy\"\n",
    "\n",
    "# default\n",
    "config_file = \"./FourCastNet/config/AFNO.yaml\"\n",
    "config_name = \"afno_backbone\"\n",
    "params = YParams(config_file, config_name)\n",
    "print(\"Model architecture used = {}\".format(params[\"nettype\"]))\n",
    "\n",
    "if PLOT_INPUTS:\n",
    "    sample_data = h5py.File(data_file, 'r')['fields']\n",
    "    print('Total data shape:', sample_data.shape)\n",
    "    timestep_idx = 0\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "    for i, varname in enumerate(['u10', 't2m', 'z500', 'tcwv']):\n",
    "        cm = 'bwr' if varname == 'u10' or varname == 'z500' else 'viridis'\n",
    "        varidx = VARIABLES.index(varname)\n",
    "        ax[i//2][i%2].imshow(sample_data[timestep_idx, varidx], cmap=cm)\n",
    "        ax[i//2][i%2].set_title(varname)\n",
    "    fig.tight_layout()\n",
    "\n",
    "# import model\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# in and out channels: FourCastNet uses 20 input channels corresponding to 20 prognostic variables\n",
    "in_channels = np.array(params.in_channels)\n",
    "out_channels = np.array(params.out_channels)\n",
    "params['N_in_channels'] = len(in_channels)\n",
    "params['N_out_channels'] = len(out_channels)\n",
    "params.means = np.load(global_means_path)[0, out_channels] # for normalizing data with precomputed train stats\n",
    "params.stds = np.load(global_stds_path)[0, out_channels]\n",
    "params.time_means = np.load(time_means_path)[0, out_channels]\n",
    "\n",
    "# load the model\n",
    "if params.nettype == 'afno':\n",
    "    model = AFNONet(params).to(device)  # AFNO model\n",
    "else:\n",
    "    raise Exception(\"not implemented\")\n",
    "# load saved model weights\n",
    "model = load_model(model, params, model_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db2c516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of time means = torch.Size([1, 20, 720, 1440])\n",
      "Shape of std = torch.Size([20])\n",
      "Loading inference data\n",
      "Inference data from /pscratch/sd/m/mpowell/hpml/ccai_demo/data/FCN_ERA5_data_v0/out_of_sample/2018.h5\n",
      "(20, 20, 720, 1440)\n",
      "Shape of data = (20, 20, 720, 1440)\n"
     ]
    }
   ],
   "source": [
    "# move normalization tensors to gpu\n",
    "# load time means: represents climatology\n",
    "img_shape_x = 720\n",
    "img_shape_y = 1440\n",
    "\n",
    "# means and stds over training data\n",
    "means = params.means\n",
    "stds = params.stds\n",
    "\n",
    "# load climatological means\n",
    "time_means = params.time_means # temporal mean (for every pixel)\n",
    "m = torch.as_tensor((time_means - means)/stds)[:, 0:img_shape_x]\n",
    "m = torch.unsqueeze(m, 0)\n",
    "# these are needed to compute ACC and RMSE metrics\n",
    "m = m.to(device, dtype=torch.float)\n",
    "std = torch.as_tensor(stds[:,0,0]).to(device, dtype=torch.float)\n",
    "\n",
    "print(\"Shape of time means = {}\".format(m.shape))\n",
    "print(\"Shape of std = {}\".format(std.shape))\n",
    "\n",
    "# setup data for inference\n",
    "dt = 1 # time step (x 6 hours)\n",
    "ic = 0 # start the inference from here\n",
    "prediction_length = 20 # number of steps (x 6 hours)\n",
    "\n",
    "# which field to track for visualization\n",
    "field = 'u10'\n",
    "idx_vis = VARIABLES.index(field) # also prints out metrics for this field\n",
    "\n",
    "# get prediction length slice from the data\n",
    "print('Loading inference data')\n",
    "print('Inference data from {}'.format(data_file))\n",
    "data = h5py.File(data_file, 'r')['fields'][ic:(ic+prediction_length*dt):dt,in_channels,0:img_shape_x]\n",
    "print(data.shape)\n",
    "print(\"Shape of data = {}\".format(data.shape))\n",
    "\n",
    "data = (data - means)/stds # standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24b7bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 720, 1440)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7db4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[np.newaxis, :, :, :]\n",
    "ensemble_size = 2\n",
    "\n",
    "# replicate to create an ensemble and add a small perturbation (e.g., 1e-3 scaling factor)\n",
    "ensemble_init = data.repeat(ensemble_size, axis = 0)\n",
    "ensemble_init = torch.tensor(ensemble_init, device=device, dtype=torch.float)\n",
    "\n",
    "epsilon = 1e-3  # perturbation magnitude\n",
    "ensemble_init += epsilon * torch.randn_like(ensemble_init.clone().detach())\n",
    "\n",
    "# Set the prediction length (number of autoregressive steps)\n",
    "prediction_length = 20  # as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd9a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rmse_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    #takes in arrays of size [n, c, h, w]  and returns latitude-weighted rmse for each channel\n",
    "    num_lat = pred.shape[2]\n",
    "    lat_t = torch.arange(start=0, end=num_lat, device=pred.device)\n",
    "    s = torch.sum(torch.cos(3.1416/180. * lat(lat_t, num_lat)))\n",
    "    weight = torch.reshape(latitude_weighting_factor(lat_t, num_lat, s), (1, 1, -1, 1))\n",
    "    result = torch.sqrt(torch.mean(weight * (pred - target)**2., dim=(-1,-2)))\n",
    "    return result\n",
    "\n",
    "def weighted_acc_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    #takes in arrays of size [n, c, h, w]  and returns latitude-weighted acc for each channel\n",
    "    num_lat = pred.shape[2]\n",
    "    lat_t = torch.arange(start=0, end=num_lat, device=pred.device)\n",
    "    s = torch.sum(torch.cos(3.1416/180. * lat(lat_t, num_lat)))\n",
    "    weight = torch.reshape(latitude_weighting_factor(lat_t, num_lat, s), (1, 1, -1, 1))\n",
    "    result = torch.sum(weight * pred * target, dim=(-1,-2)) / torch.sqrt(torch.sum(weight * pred * pred, dim=(-1,-2)) * torch.sum(weight * target *\n",
    "    target, dim=(-1,-2)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a43b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.utils import gather_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68761a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble 0, Predicted timestep 0 of 20. u10 RMS Error: 0.0, ACC: 1.0\n",
      "Ensemble 0, Predicted timestep 1 of 20. u10 RMS Error: 0.5597086548805237, ACC: 0.9900749325752258\n",
      "Ensemble 0, Predicted timestep 2 of 20. u10 RMS Error: 0.7683301568031311, ACC: 0.9802830815315247\n",
      "Ensemble 0, Predicted timestep 3 of 20. u10 RMS Error: 0.8545392751693726, ACC: 0.9751363396644592\n",
      "Ensemble 0, Predicted timestep 4 of 20. u10 RMS Error: 0.9781058430671692, ACC: 0.9663190245628357\n",
      "Ensemble 0, Predicted timestep 5 of 20. u10 RMS Error: 1.0724717378616333, ACC: 0.960019588470459\n",
      "Ensemble 0, Predicted timestep 6 of 20. u10 RMS Error: 1.2342443466186523, ACC: 0.9463395476341248\n",
      "Ensemble 0, Predicted timestep 7 of 20. u10 RMS Error: 1.3776659965515137, ACC: 0.9345206022262573\n",
      "Ensemble 0, Predicted timestep 8 of 20. u10 RMS Error: 1.5806593894958496, ACC: 0.9138028621673584\n",
      "Ensemble 0, Predicted timestep 9 of 20. u10 RMS Error: 1.7355575561523438, ACC: 0.9003575444221497\n",
      "Ensemble 0, Predicted timestep 10 of 20. u10 RMS Error: 1.9259299039840698, ACC: 0.8789863586425781\n",
      "Ensemble 0, Predicted timestep 11 of 20. u10 RMS Error: 2.1224782466888428, ACC: 0.8570806980133057\n",
      "Ensemble 0, Predicted timestep 12 of 20. u10 RMS Error: 2.304115056991577, ACC: 0.8303134441375732\n",
      "Ensemble 0, Predicted timestep 13 of 20. u10 RMS Error: 2.497657299041748, ACC: 0.8088512420654297\n",
      "Ensemble 0, Predicted timestep 14 of 20. u10 RMS Error: 2.743441343307495, ACC: 0.7701724171638489\n",
      "Ensemble 0, Predicted timestep 15 of 20. u10 RMS Error: 2.963942527770996, ACC: 0.7335493564605713\n",
      "Ensemble 0, Predicted timestep 16 of 20. u10 RMS Error: 3.165172576904297, ACC: 0.6909683346748352\n",
      "Ensemble 0, Predicted timestep 17 of 20. u10 RMS Error: 3.316859245300293, ACC: 0.6700501441955566\n",
      "Ensemble 0, Predicted timestep 18 of 20. u10 RMS Error: 3.40173077583313, ACC: 0.6362704634666443\n",
      "Ensemble 0, Predicted timestep 19 of 20. u10 RMS Error: 3.4155631065368652, ACC: 0.6137136816978455\n",
      "Ensemble 0, Total inference time: 0.34s, Average time per step: 0.02s\n",
      "Ensemble 1, Predicted timestep 0 of 20. u10 RMS Error: 0.0, ACC: 1.0\n",
      "Ensemble 1, Predicted timestep 1 of 20. u10 RMS Error: 0.5597187280654907, ACC: 0.9900744557380676\n",
      "Ensemble 1, Predicted timestep 2 of 20. u10 RMS Error: 0.7683627009391785, ACC: 0.9802813529968262\n",
      "Ensemble 1, Predicted timestep 3 of 20. u10 RMS Error: 0.8544873595237732, ACC: 0.9751393795013428\n",
      "Ensemble 1, Predicted timestep 4 of 20. u10 RMS Error: 0.9777160286903381, ACC: 0.9663462042808533\n",
      "Ensemble 1, Predicted timestep 5 of 20. u10 RMS Error: 1.0717672109603882, ACC: 0.9600719809532166\n",
      "Ensemble 1, Predicted timestep 6 of 20. u10 RMS Error: 1.2331852912902832, ACC: 0.946429967880249\n",
      "Ensemble 1, Predicted timestep 7 of 20. u10 RMS Error: 1.3761608600616455, ACC: 0.934661328792572\n",
      "Ensemble 1, Predicted timestep 8 of 20. u10 RMS Error: 1.5790636539459229, ACC: 0.9139759540557861\n",
      "Ensemble 1, Predicted timestep 9 of 20. u10 RMS Error: 1.7334706783294678, ACC: 0.9005973935127258\n",
      "Ensemble 1, Predicted timestep 10 of 20. u10 RMS Error: 1.924163818359375, ACC: 0.8792056441307068\n",
      "Ensemble 1, Predicted timestep 11 of 20. u10 RMS Error: 2.120849370956421, ACC: 0.8572977781295776\n",
      "Ensemble 1, Predicted timestep 12 of 20. u10 RMS Error: 2.3026981353759766, ACC: 0.8305248022079468\n",
      "Ensemble 1, Predicted timestep 13 of 20. u10 RMS Error: 2.497345209121704, ACC: 0.808897852897644\n",
      "Ensemble 1, Predicted timestep 14 of 20. u10 RMS Error: 2.7436435222625732, ACC: 0.7701297402381897\n",
      "Ensemble 1, Predicted timestep 15 of 20. u10 RMS Error: 2.9644107818603516, ACC: 0.7334501147270203\n",
      "Ensemble 1, Predicted timestep 16 of 20. u10 RMS Error: 3.165863275527954, ACC: 0.690834641456604\n",
      "Ensemble 1, Predicted timestep 17 of 20. u10 RMS Error: 3.3164374828338623, ACC: 0.6701163649559021\n",
      "Ensemble 1, Predicted timestep 18 of 20. u10 RMS Error: 3.4004595279693604, ACC: 0.6365318298339844\n",
      "Ensemble 1, Predicted timestep 19 of 20. u10 RMS Error: 3.4147801399230957, ACC: 0.6139135956764221\n",
      "Ensemble 1, Total inference time: 0.34s, Average time per step: 0.02s\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "# Prepare model with Accelerate\n",
    "model = accelerator.prepare(model)\n",
    "\n",
    "# Divide ensemble members among processes\n",
    "local_ensemble_size = (ensemble_size + accelerator.num_processes - 1) // accelerator.num_processes\n",
    "start_idx = accelerator.process_index * local_ensemble_size\n",
    "end_idx = min(start_idx + local_ensemble_size, ensemble_size)\n",
    "local_ensemble_range = range(start_idx, end_idx)\n",
    "\n",
    "# Process local ensemble members\n",
    "local_results = []\n",
    "for i in local_ensemble_range:\n",
    "    data_slice = ensemble_init[i]\n",
    "    idx = idx_vis\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Warmup pass\n",
    "        dummy_input = torch.randn(1, data_slice.shape[1], img_shape_x, img_shape_y).to(device)\n",
    "        _ = model(dummy_input)\n",
    "    \n",
    "    # Create memory for the different stats\n",
    "    n_out_channels = params['N_out_channels']\n",
    "    acc = torch.zeros((prediction_length, n_out_channels)).to(device, dtype=torch.float)\n",
    "    rmse = torch.zeros((prediction_length, n_out_channels)).to(device, dtype=torch.float)\n",
    "\n",
    "    targets = torch.zeros((prediction_length, 1, img_shape_x, img_shape_y)).to(device, dtype=torch.float)\n",
    "    predictions = torch.zeros((prediction_length, 1, img_shape_x, img_shape_y)).to(device, dtype=torch.float)\n",
    "    \n",
    "    total_time = 0\n",
    "    with torch.no_grad():\n",
    "        for j in range(data_slice.shape[0]):\n",
    "            iter_start = time.time()\n",
    "            if j == 0:\n",
    "                first = data_slice[0:1]\n",
    "                future = data_slice[1:2]\n",
    "                pred = first\n",
    "                tar = first\n",
    "                # Predict\n",
    "                future_pred = model(first)\n",
    "            else:\n",
    "                if j < prediction_length - 1:\n",
    "                    future = data_slice[j+1:j+2]\n",
    "                future_pred = model(future_pred)  # Autoregressive step\n",
    "            \n",
    "            if j < prediction_length - 1:\n",
    "                predictions[j+1, 0] = future_pred[0, idx]\n",
    "                targets[j+1, 0] = future[0, idx]\n",
    "            rmse[j] = weighted_rmse_channels(pred, tar) * std\n",
    "            acc[j] = weighted_acc_channels(pred-m, tar-m)\n",
    "            iter_time = time.time() - iter_start\n",
    "            \n",
    "            if accelerator.is_main_process:  # Only main process logs\n",
    "                print(f'Ensemble {i}, Predicted timestep {j} of {prediction_length}. {field} RMS Error: {rmse[j, idx]}, ACC: {acc[j, idx]}')\n",
    "            \n",
    "            pred = future_pred\n",
    "            tar = future\n",
    "            total_time += iter_time\n",
    "            \n",
    "    avg_time = total_time / prediction_length\n",
    "    if accelerator.is_main_process:\n",
    "        print(f'Ensemble {i}, Total inference time: {total_time:.2f}s, Average time per step: {avg_time:.2f}s')\n",
    "    \n",
    "    # Save local results\n",
    "    local_results.append({\n",
    "        'ensemble_idx': i,\n",
    "        'acc': acc.cpu().numpy(),\n",
    "        'rmse': rmse.cpu().numpy(),\n",
    "        'total_time': total_time,\n",
    "        'avg_time': avg_time\n",
    "    })\n",
    "\n",
    "gathered_results = gather_object(local_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "523d2d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensemble_idx</th>\n",
       "      <th>acc</th>\n",
       "      <th>rmse</th>\n",
       "      <th>total_time</th>\n",
       "      <th>avg_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.339268</td>\n",
       "      <td>0.016963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.339779</td>\n",
       "      <td>0.016989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ensemble_idx                                                acc  \\\n",
       "0             0  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "1             1  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "\n",
       "                                                rmse  total_time  avg_time  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    0.339268  0.016963  \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    0.339779  0.016989  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(gathered_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8f531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c8785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
